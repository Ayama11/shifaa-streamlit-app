import streamlit as st
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

MODEL_ID = "aya99ma/shifaa-bert-classifier"

st.set_page_config(page_title="Shifaa Question Classifier", page_icon="๐ฉบ", layout="centered")

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)
    model.eval()
    return tokenizer, model

tokenizer, model = load_model()

st.title("๐ฉบ ุชุตููู ุฃุณุฆูุฉ ุดูุงุก ุงูุทุจูุฉ")
text = st.text_area("ุงูุชุจ ุงูุณุคุงู ุงูุทุจู ููุง:", height=120)

top_k = st.slider("ุนุฏุฏ ุงูุชุตูููุงุช ุงููุนุฑูุถุฉ", 1, 5, 3)

if st.button("ุตููู ุงูุณุคุงู"):
    if not text.strip():
        st.warning("ูู ูุถูู ุงูุชุจ ุณุคุงููุง ุฃูููุง.")
    else:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)

        with torch.no_grad():
            logits = model(**inputs).logits
            probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]

        top_idx = probs.argsort()[::-1][:top_k]
        st.subheader("ุงููุชุงุฆุฌ:")
        for i in top_idx:
            st.write(f"- **{model.config.id2label[i]}** : {probs[i]*100:.2f}%")
