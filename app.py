import streamlit as st
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

MODEL_ID = "aya99ma/shifaa-bert-classifier"

# ุชุญููู LABEL_x ุฅูู ุฃุณูุงุก ุนุฑุจูุฉ
LABELS_AR = {
    "LABEL_0": "ุฃูุฑุงุถ ุงูุฃุทูุงู ููุดุงูููู",
    "LABEL_1": "ุฃูุฑุงุถ ุงูุจุงุทููุฉ ูุงูุตุฏุฑ",
    "LABEL_2": "ุฃูุฑุงุถ ุงูุฌูุฏูุฉ",
    "LABEL_3": "ุฃูุฑุงุถ ุงูุฌูุงุฒ ุงูุจููู ูุงูุชูุงุณูู",
    "LABEL_4": "ุฃูุฑุงุถ ุงูุฌูุงุฒ ุงูุนุตุจู",
    "LABEL_5": "ุฃูุฑุงุถ ุงูุฏู ูุงูุฃูุฑุงู",
    "LABEL_6": "ุฃูุฑุงุถ ุงูุฑุฃุณ",
    "LABEL_7": "ุฃูุฑุงุถ ุงูุนุถูุงุช",
    "LABEL_8": "ุฃูุฑุงุถ ุงูุนุธุงู",
    "LABEL_9": "ุฃูุฑุงุถ ุงูุบุฏุฏ ูุงููุฑูููุงุช",
    "LABEL_10": "ุฃูุฑุงุถ ุงููุณุงุก ูุงูููุงุฏุฉ",
    "LABEL_11": "ุงูุฃุฏููุฉ ูุงููุณุชุญุถุฑุงุช",
    "LABEL_12": "ุงูุฌุฑุงุญุฉ ุงูุนุงูุฉ ูุงูุชุฌููู",
    "LABEL_13": "ุงูุตุญุฉ ุงูุจุฏููุฉ",
    "LABEL_14": "ุงูุทุจ ุงูุจุฏูู",
    "LABEL_15": "ุดุฆูู ุทุจูุฉ ููุดุงูู ูุชูุฑูุฉ",
}

st.set_page_config(page_title="Shifaa Question Classifier", page_icon="๐ฉบ", layout="centered")

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)
    model.eval()
    return tokenizer, model

tokenizer, model = load_model()

st.title("๐ฉบ ุชุตููู ุฃุณุฆูุฉ ุดูุงุก ุงูุทุจูุฉ")
text = st.text_area("ุงูุชุจ ุงูุณุคุงู ุงูุทุจู ููุง:", height=120)

top_k = st.slider("ุนุฏุฏ ุงูุชุตูููุงุช ุงููุนุฑูุถุฉ", 1, 5, 3)

if st.button("ุตููู ุงูุณุคุงู"):
    if not text.strip():
        st.warning("ูู ูุถูู ุงูุชุจ ุณุคุงููุง ุฃูููุง.")
    else:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)

        with torch.no_grad():
            logits = model(**inputs).logits
            probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]

        top_idx = probs.argsort()[::-1][:top_k]
        st.subheader("ุงููุชุงุฆุฌ:")
        for i in top_idx:
            label_en = model.config.id2label[i]
            label_ar = LABELS_AR.get(label_en, label_en)
            st.write(f"- **{label_ar}** : {probs[i]*100:.2f}%")
