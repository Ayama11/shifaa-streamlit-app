import os
import time
import streamlit as st
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ===== Performance / Stability =====
os.environ["TOKENIZERS_PARALLELISM"] = "false"
torch.set_num_threads(1)

MODEL_ID = "aya99ma/shifaa-bert-classifier"


GITHUB_REPO_URL = "https://github.com/Ayama11/shifaa-streamlit-app"
HF_MODEL_URL = f"https://huggingface.co/{MODEL_ID}"

# Model metrics (as provided)
METRICS = {
    "Accuracy": 0.82,
    "F1-macro": 0.70,
}

# Arabic labels mapping (from your label_encoder)
LABELS_AR = {
    "LABEL_0": "ุฃูุฑุงุถ ุงูุฃุทูุงู ููุดุงูููู",
    "LABEL_1": "ุฃูุฑุงุถ ุงูุจุงุทููุฉ ูุงูุตุฏุฑ",
    "LABEL_2": "ุฃูุฑุงุถ ุงูุฌูุฏูุฉ",
    "LABEL_3": "ุฃูุฑุงุถ ุงูุฌูุงุฒ ุงูุจููู ูุงูุชูุงุณูู",
    "LABEL_4": "ุฃูุฑุงุถ ุงูุฌูุงุฒ ุงูุนุตุจู",
    "LABEL_5": "ุฃูุฑุงุถ ุงูุฏู ูุงูุฃูุฑุงู",
    "LABEL_6": "ุฃูุฑุงุถ ุงูุฑุฃุณ",
    "LABEL_7": "ุฃูุฑุงุถ ุงูุนุถูุงุช",
    "LABEL_8": "ุฃูุฑุงุถ ุงูุนุธุงู",
    "LABEL_9": "ุฃูุฑุงุถ ุงูุบุฏุฏ ูุงููุฑูููุงุช",
    "LABEL_10": "ุฃูุฑุงุถ ุงููุณุงุก ูุงูููุงุฏุฉ",
    "LABEL_11": "ุงูุฃุฏููุฉ ูุงููุณุชุญุถุฑุงุช",
    "LABEL_12": "ุงูุฌุฑุงุญุฉ ุงูุนุงูุฉ ูุงูุชุฌููู",
    "LABEL_13": "ุงูุตุญุฉ ุงูุจุฏููุฉ",
    "LABEL_14": "ุงูุทุจ ุงูุจุฏูู",
    "LABEL_15": "ุดุฆูู ุทุจูุฉ ููุดุงูู ูุชูุฑูุฉ",
}

st.set_page_config(
    page_title="Shifaa Question Classifier",
    page_icon="๐ฉบ",
    layout="centered",
)

# ===== Minimal, responsive RTL styling (no fixed widths) =====
st.markdown("""
<style>
html, body, [class*="css"]  { direction: rtl; text-align: right; }
.block-container { padding-top: 1.8rem; max-width: 920px; }

.small-muted { opacity: 0.78; font-size: 0.95rem; line-height: 1.5; }
.kpi { opacity: 0.88; font-size: 0.92rem; }

.card {
    border: 1px solid rgba(255,255,255,0.10);
    border-radius: 16px;
    padding: 14px 16px;
    background: rgba(255,255,255,0.03);
    margin-bottom: 12px;
}

.card-strong {
    border: 1px solid rgba(255,255,255,0.14);
    background: rgba(255,255,255,0.05);
}

.badge {
    display: inline-block;
    padding: 4px 10px;
    border-radius: 999px;
    border: 1px solid rgba(255,255,255,0.14);
    font-size: 0.85rem;
    opacity: 0.9;
}

div.stButton > button {
    width: 100%;
    border-radius: 14px;
    padding: 0.7rem 1rem;
    font-weight: 800;
}

a.cleanlink { text-decoration: none; }
a.cleanlink:hover { text-decoration: underline; }

footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_model():
    tok = AutoTokenizer.from_pretrained(MODEL_ID)
    mdl = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)
    mdl.eval()
    return tok, mdl

with st.spinner("ุฌุงุฑู ุชุญููู ุงูููุฏูู... (ูุฏ ูุณุชุบุฑู ุฐูู ุฃูู ูุฑุฉ)"):
    tokenizer, model = load_model()

# ===== Header =====
st.title("๐ฉบ ุชุตููู ุฃุณุฆูุฉ ุดูุงุก ุงูุทุจูุฉ")
st.markdown(
    '<div class="small-muted">'
    'ูููุฐุฌ ูุชุตููู ุงูุฃุณุฆูุฉ ุงูุทุจูุฉ ุฅูู <b>16</b> ูุฆุฉ ุจุงุณุชุฎุฏุงู BERT (Fine-tuned). '
    'ููุฃุบุฑุงุถ ุงูุจุญุซูุฉ/ุงูุนุฑุถ ููุท.'
    '</div>',
    unsafe_allow_html=True
)

# Quick links (clickable)
st.markdown(
    f"""
<div class="small-muted">
  ๐ <a class="cleanlink" href="{GITHUB_REPO_URL}" target="_blank"><b>GitHub Repo</b></a>
  &nbsp; | &nbsp;
  ๐ค <a class="cleanlink" href="{HF_MODEL_URL}" target="_blank"><b>HuggingFace Model</b></a>
</div>
""",
    unsafe_allow_html=True
)

st.divider()

# ===== Input Section (Stacked for mobile friendliness) =====
st.markdown('<div class="card">', unsafe_allow_html=True)

question = st.text_area(
    "ุงูุชุจ ุงูุณุคุงู ุงูุทุจู ููุง:",
    height=160,
    placeholder="ูุซุงู: ูุฏู ุตุฏุงุน ุดุฏูุฏ ููุฐ ููููู ูุน ุฏูุฎุฉุ ูุง ุงูุณุจุจ ุงููุญุชููุ"
)

top_k = st.slider("ุนุฏุฏ ุงูุชุตูููุงุช ุงููุนุฑูุถุฉ", 1, 5, 3)
show_all_probs = st.checkbox("ุนุฑุถ ุฌููุน ุงูุงุญุชูุงูุงุช", value=False)

classify = st.button("ุตููู ุงูุณุคุงู")

st.markdown('</div>', unsafe_allow_html=True)

# ===== Inference =====
if classify:
    if not question.strip():
        st.warning("ูู ูุถูู ุงูุชุจ ุณุคุงููุง ุฃูููุง.")
    else:
        t0 = time.perf_counter()

        inputs = tokenizer(
            question,
            return_tensors="pt",
            truncation=True,
            padding=True,
        )

        with torch.inference_mode():
            logits = model(**inputs).logits
            probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]

        ms = (time.perf_counter() - t0) * 1000.0

        order = probs.argsort()[::-1]
        top_idx = order[:top_k]

        # Top-1
        i0 = int(top_idx[0])
        label0_en = model.config.id2label[i0]
        label0_ar = LABELS_AR.get(label0_en, label0_en)
        p0 = float(probs[i0])

        st.subheader("ุงููุชุงุฆุฌ")

        st.markdown(
            f"""
            <div class="card card-strong">
              <div style="display:flex; justify-content:space-between; align-items:center; gap:10px;">
                <div style="font-weight:900; font-size:1.08rem;">{label0_ar}</div>
                <div class="badge">{p0*100:.2f}%</div>
              </div>
              <div class="kpi" style="margin-top:8px;">
                ุฒูู ุงูุงุณุชุฌุงุจุฉ: <b>{ms:.0f} ms</b>
              </div>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.progress(p0)

        # Remaining Top-k
        if len(top_idx) > 1:
            st.markdown("##### ุฃุนูู ุชุตูููุงุช ุฃุฎุฑู")
            for i in top_idx[1:]:
                i = int(i)
                label_en = model.config.id2label[i]
                label_ar = LABELS_AR.get(label_en, label_en)
                p = float(probs[i])

                st.markdown(
                    f"""
                    <div class="card">
                      <div style="display:flex; justify-content:space-between; align-items:center; gap:10px;">
                        <div style="font-weight:800;">{label_ar}</div>
                        <div class="badge">{p*100:.2f}%</div>
                      </div>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.progress(p)

        # Optional: show all probabilities
        if show_all_probs:
            st.divider()
            st.markdown("### ุฌููุน ุงูุงุญุชูุงูุงุช")
            for i in order:
                i = int(i)
                label_en = model.config.id2label[i]
                label_ar = LABELS_AR.get(label_en, label_en)
                p = float(probs[i])
                st.write(f"- {label_ar}: {p*100:.2f}%")

# ===== Footer / Project Info (Bottom, responsive) =====
st.divider()

st.markdown(
    f"""
<div class="card">
  <div style="font-weight:900; font-size:1.05rem; margin-bottom:6px;">ุนู ุงููุดุฑูุน</div>

  <div class="small-muted">
    ูุฐุง ุงูุนูู ููุฏูู ูููุฐุฌูุง ูุชุตููู ุฃุณุฆูุฉ ููุตุฉ ุดูุงุก ุงูุทุจูุฉ ุฅูู 16 ูุฆุฉ ุจุงุณุชุฎุฏุงู BERT ุจุนุฏ Fine-tuning.
    ุงููุฏู ูู ุนุฑุถ ุชุฌุฑุจุฉ NLP ูุงููุฉ ุชุดูู ุงูุชุฏุฑูุจุ ุงูุชููููุ ุซู ูุดุฑ ูุงุฌูุฉ ุชูุงุนููุฉ ุนุจุฑ Streamlit.
  </div>

  <div style="margin-top:12px;">
    <span class="badge">Accuracy โ {METRICS["Accuracy"]:.2f}</span>
    &nbsp;
    <span class="badge">F1-macro โ {METRICS["F1-macro"]:.2f}</span>
  </div>

  <div class="small-muted" style="margin-top:12px;">
    <b>ุงูููุฏูู:</b> <a class="cleanlink" href="{HF_MODEL_URL}" target="_blank">{MODEL_ID}</a>
    &nbsp; | &nbsp;
    <b>ุงููุตุฏุฑ:</b> <a class="cleanlink" href="{GITHUB_REPO_URL}" target="_blank">GitHub</a>
  </div>

  <div class="small-muted" style="margin-top:10px;">
    ุชูุจูู: ุงููุชุงุฆุฌ ูุนูููุงุชูุฉ ููุง ุชุบูู ุนู ุงุณุชุดุงุฑุฉ ุทุจูุจ ูุฎุชุต.
  </div>
</div>
""",
    unsafe_allow_html=True
)
